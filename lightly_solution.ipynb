{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#instalar docker\n",
        "!apt-get -qq install docker.io"
      ],
      "metadata": {
        "id": "B5ia8CyrUdJI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check version.\n",
        "!docker --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I98jY75KUjgZ",
        "outputId": "512e346c-6a26-427e-c390-91132d261b8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Docker version 24.0.5, build 24.0.5-0ubuntu1~22.04.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "set -x\n",
        "dockerd -b none --iptables=0 -l warn &\n",
        "for i in $(seq 5); do [ ! -S \"/var/run/docker.sock\" ] && sleep 2 || break; done\n",
        "docker info\n",
        "docker network ls\n",
        "docker pull hello-world\n",
        "docker images\n",
        "docker run hello-world\n",
        "kill $(jobs -p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLn8Lyu-Ulsz",
        "outputId": "86f417b2-81ee-4e07-c25b-88f366b7a67d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ dockerd -b none --iptables=0 -l warn\n",
            "++ seq 5\n",
            "+ for i in $(seq 5)\n",
            "+ '[' '!' -S /var/run/docker.sock ']'\n",
            "+ sleep 2\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:35.885642146Z] failed to load plugin io.containerd.snapshotter.v1.devmapper  \u001b[33merror\u001b[0m=\"devmapper not configured\"\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:35.885864830Z] could not use snapshotter devmapper in metadata plugin  \u001b[33merror\u001b[0m=\"devmapper not configured\"\n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:35.922897958Z] failed to mount overlay: invalid argument     \u001b[31mstorage-driver\u001b[0m=overlay2\n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:35.923038459Z] exec: \"fuse-overlayfs\": executable file not found in $PATH  \u001b[31mstorage-driver\u001b[0m=fuse-overlayfs\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:35.963055384Z] Failed to disable IPv6 on all interfaces on network namespace \"/var/run/docker/netns/4a5010508663\": failed to disable IPv6 forwarding for container's interface all: open /proc/sys/net/ipv6/conf/all/disable_ipv6: read-only file system \n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:35.963229687Z] failed to create osl sandbox while trying to restore sandbox 4a50105 for cleanup: operation not permitted \n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:35.963989139Z] Failed to disable IPv6 on all interfaces on network namespace \"/var/run/docker/netns/bd59cf4637a7\": failed to disable IPv6 forwarding for container's interface all: open /proc/sys/net/ipv6/conf/all/disable_ipv6: read-only file system \n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:35.964088831Z] failed to create osl sandbox while trying to restore sandbox bd59cf4 for cleanup: operation not permitted \n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:35.979216271Z] WARNING: No swap limit support               \n",
            "+ for i in $(seq 5)\n",
            "+ '[' '!' -S /var/run/docker.sock ']'\n",
            "+ break\n",
            "+ docker info\n",
            "Client:\n",
            " Version:    24.0.5\n",
            " Context:    default\n",
            " Debug Mode: false\n",
            "\n",
            "Server:\n",
            " Containers: 2\n",
            "  Running: 0\n",
            "  Paused: 0\n",
            "  Stopped: 2\n",
            " Images: 1\n",
            " Server Version: 24.0.5\n",
            " Storage Driver: vfs\n",
            " Logging Driver: json-file\n",
            " Cgroup Driver: cgroupfs\n",
            " Cgroup Version: 2\n",
            " Plugins:\n",
            "  Volume: local\n",
            "  Network: bridge host ipvlan macvlan null overlay\n",
            "  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\n",
            " Swarm: inactive\n",
            " Runtimes: io.containerd.runc.v2 runc\n",
            " Default Runtime: runc\n",
            " Init Binary: docker-init\n",
            " containerd version: \n",
            " runc version: \n",
            " init version: fec3683b971d9c3ef73f284f176672c44b448662\n",
            " Security Options:\n",
            "  seccomp\n",
            "   Profile: builtin\n",
            "  cgroupns\n",
            " Kernel Version: 6.1.58+\n",
            " Operating System: Ubuntu 22.04.3 LTS\n",
            " OSType: linux\n",
            " Architecture: x86_64\n",
            " CPUs: 2\n",
            " Total Memory: 12.67GiB\n",
            " Name: 613ededf1f25\n",
            " ID: ccc922af-8860-4895-91a5-be49d7f13c72\n",
            " Docker Root Dir: /var/lib/docker\n",
            " Debug Mode: false\n",
            " Experimental: false\n",
            " Insecure Registries:\n",
            "  127.0.0.0/8\n",
            " Live Restore Enabled: false\n",
            "\n",
            "WARNING: No swap limit support\n",
            "+ docker network ls\n",
            "NETWORK ID     NAME      DRIVER    SCOPE\n",
            "2c1f6153d867   host      host      local\n",
            "98f1cf20a3cf   none      null      local\n",
            "+ docker pull hello-world\n",
            "Using default tag: latest\n",
            "latest: Pulling from library/hello-world\n",
            "Digest: sha256:a26bff933ddc26d5cdf7faa98b4ae1e3ec20c4985e6f87ac0973052224d24302\n",
            "Status: Image is up to date for hello-world:latest\n",
            "docker.io/library/hello-world:latest\n",
            "+ docker images\n",
            "REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\n",
            "hello-world   latest    d2c94e258dcb   12 months ago   13.3kB\n",
            "+ docker run hello-world\n",
            "time=\"2024-05-02T14:25:38.946483582Z\" level=info msg=\"loading plugin \\\"io.containerd.internal.v1.shutdown\\\"...\" runtime=io.containerd.runc.v2 type=io.containerd.internal.v1\n",
            "time=\"2024-05-02T14:25:38.946573299Z\" level=info msg=\"loading plugin \\\"io.containerd.ttrpc.v1.pause\\\"...\" runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1\n",
            "time=\"2024-05-02T14:25:38.946592001Z\" level=info msg=\"loading plugin \\\"io.containerd.event.v1.publisher\\\"...\" runtime=io.containerd.runc.v2 type=io.containerd.event.v1\n",
            "time=\"2024-05-02T14:25:38.946602484Z\" level=info msg=\"loading plugin \\\"io.containerd.ttrpc.v1.task\\\"...\" runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:38.969269221Z] cleaning up after shim disconnected           \u001b[33mid\u001b[0m=4810a33cc4146f88781a77674c7f88f47ac07ea03b9f8da43202d2b860ab26fa \u001b[33mnamespace\u001b[0m=moby\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T14:25:38.984837264Z] cleanup warnings time=\"2024-05-02T14:25:38Z\" level=warning msg=\"failed to read init pid file\" error=\"open /run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/4810a33cc4146f88781a77674c7f88f47ac07ea03b9f8da43202d2b860ab26fa/init.pid: no such file or directory\" runtime=io.containerd.runc.v2  \u001b[33mnamespace\u001b[0m=moby\n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:38.986199332Z] copy shim log                                 \u001b[31merror\u001b[0m=\"read /proc/self/fd/13: file already closed\" \u001b[31mnamespace\u001b[0m=moby\n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:38.987205527Z] stream copy error: reading from a closed fifo \n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:38.988199196Z] stream copy error: reading from a closed fifo \n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T14:25:39.004968813Z] Handler for POST /v1.43/containers/4810a33cc4146f88781a77674c7f88f47ac07ea03b9f8da43202d2b860ab26fa/start returned error: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: unable to apply cgroup configuration: mkdir /sys/fs/cgroup/docker: read-only file system: unknown \n",
            "docker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: unable to apply cgroup configuration: mkdir /sys/fs/cgroup/docker: read-only file system: unknown.\n",
            "\u001b[31mERRO\u001b[0m[0000] error waiting for container:                 \n",
            "++ jobs -p\n",
            "+ kill 2185\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Establezca la ruta al conjunto de datos.\n",
        "# Aquí descargamos y utilizamos un conjunto de datos que contiene 354 imágenes que muestran ropa.\n",
        "# Si desea utilizar su propio conjunto de datos, simplemente establezca dataset_path en él.\n",
        "dataset_path = \"dataset_clothing_images\"\n",
        "!git clone https://github.com/lightly-ai/dataset_clothing_images.git {dataset_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5oUODwggmIG",
        "outputId": "076f6fa9-4aa2-428d-9bad-83225909b600"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'dataset_clothing_images' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Lightly Python Client\n",
        "!pip3 install lightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2HmnkP9HV12b",
        "outputId": "0a4e1374-a8d3-4d8d-a5c6-7a8a21fd1d10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly\n",
            "  Downloading lightly-1.5.3-py3-none-any.whl (741 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.2/741.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2024.2.2)\n",
            "Collecting hydra-core>=1.0.0 (from lightly)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightly-utils~=0.0.0 (from lightly)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.31.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.0.7)\n",
            "Collecting pydantic<2,>=1.10.5 (from lightly)\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from lightly)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lightly) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly) (0.17.1+cu121)\n",
            "Collecting pytorch-lightning>=1.0.4 (from lightly)\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (24.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly-utils~=0.0.0->lightly) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.10.5->lightly) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.0.4->lightly)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.8.0 (from pytorch-lightning>=1.0.4->lightly)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->lightly)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->lightly)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->lightly)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->lightly)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->lightly)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->lightly)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->lightly)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->lightly)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.0.4->lightly) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lightly) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (4.0.3)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=ecf84467293573c1b96bb64d19dec692b822404391faedf0cf2cd6067ff56b9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, pydantic, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, lightly-utils, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightly\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "Successfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 lightly-1.5.3 lightly-utils-0.0.2 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pydantic-1.10.15 pytorch-lightning-2.2.4 torchmetrics-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "cad4e0a5835241e5ab5d9b85d84a021d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\n",
            "See 'docker run --help'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instale Lightly Worker y realice una verificación rápida de cordura\n",
        "# Si estos comandos fallan, siga nuestra guía de instalación de Docker en https://docs.lightly.ai/docs/install-lightly#docker\n",
        "!docker pull lightly/worker:latest\n",
        "!docker run --shm-size=\"1024m\" --rm -it lightly/worker:latest sanity_check=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SJaGivqsLgC",
        "outputId": "a3d7f06c-b6ac-488d-8425-ebde263b9ab9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\n",
            "See 'docker run --help'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Schedule a run\n",
        "from lightly.api import ApiWorkflowClient\n",
        "from lightly.openapi_generated.swagger_client import DatasetType, DatasourcePurpose\n",
        "\n",
        "lightly_token = \"CHANGE_ME\" # Copy the API_TOKEN from https://app.lightly.ai/preferences\n",
        "\n",
        "# Create the Lightly client to connect to the API.\n",
        "client = ApiWorkflowClient(token=lightly_token)\n",
        "\n",
        "# Register the Lightly Worker.\n",
        "worker_id = client.register_compute_worker(name=\"clothing-worker\")\n",
        "\n",
        "# Create the dataset on the Lightly Platform.\n",
        "# If a dataset with this name already exists, you have to change the name.\n",
        "client.create_dataset(\n",
        "    dataset_name=\"clothing-small\",\n",
        "    dataset_type=DatasetType.IMAGES,\n",
        ")\n",
        "\n",
        "# Configure the datasource.\n",
        "client.set_local_config(\n",
        "    purpose=DatasourcePurpose.INPUT,\n",
        ")\n",
        "client.set_local_config(\n",
        "    purpose=DatasourcePurpose.LIGHTLY,\n",
        ")\n",
        "\n",
        "# Schedule a run on the dataset to select 50 samples.\n",
        "scheduled_run_id = client.schedule_compute_worker_run(\n",
        "    worker_config={\"shutdown_when_job_finished\": True},\n",
        "    selection_config={\n",
        "        \"n_samples\": 50,\n",
        "        \"strategies\": [\n",
        "            {\"input\": {\"type\": \"EMBEDDINGS\"}, \"strategy\": {\"type\": \"DIVERSITY\"}}\n",
        "        ],\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "VVWHbfmUr-Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tener instaaldo previamete Lightly\n",
        "!docker pull lightly/worker:latest\n",
        "!docker run --shm-size=\"1024m\" --rm -it lightly/worker:latest sanity_check=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qx393xaVo89",
        "outputId": "ef380bbb-9907-476a-eafd-feec5e6106b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\n",
            "See 'docker run --help'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install lightly\n",
        "!pip3 install --upgrade lightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XpHuRF1DpkHp",
        "outputId": "6650b038-bdb7-420e-f439-77593cef8e0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly\n",
            "  Downloading lightly-1.5.3-py3-none-any.whl (741 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.2/741.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2024.2.2)\n",
            "Collecting hydra-core>=1.0.0 (from lightly)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightly-utils~=0.0.0 (from lightly)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.31.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.0.7)\n",
            "Collecting pydantic<2,>=1.10.5 (from lightly)\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from lightly)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lightly) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly) (0.17.1+cu121)\n",
            "Collecting pytorch-lightning>=1.0.4 (from lightly)\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (24.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly-utils~=0.0.0->lightly) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.10.5->lightly) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.0.4->lightly)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.8.0 (from pytorch-lightning>=1.0.4->lightly)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->lightly)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->lightly)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->lightly)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->lightly)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->lightly)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->lightly)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->lightly)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->lightly)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->lightly)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.0.4->lightly) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lightly) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (4.0.3)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4ea33a342201092aeda849085eb8a3a6f58566a630ad16436eba81ceb37ce794\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, pydantic, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, lightly-utils, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightly\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "Successfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 lightly-1.5.3 lightly-utils-0.0.2 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pydantic-1.10.15 pytorch-lightning-2.2.4 torchmetrics-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "eb72364484604a8da9b5dd315a0cb17c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightly in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2024.2.2)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.3.2)\n",
            "Requirement already satisfied: lightly-utils~=0.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.31.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.0.7)\n",
            "Requirement already satisfied: pydantic<2,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.10.15)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from lightly) (3.1.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lightly) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly) (0.17.1+cu121)\n",
            "Requirement already satisfied: pytorch-lightning>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.2.4)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (24.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly-utils~=0.0.0->lightly) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.10.5->lightly) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (1.3.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.4->lightly) (0.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->lightly) (12.4.127)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.0.4->lightly) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lightly) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.0.4->lightly) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#INSTALAR DOCKER\n",
        "%%shell\n",
        "sudo curl -fsSL https://get.docker.com/ | sh\n",
        "sudo usermod -aG docker root\n",
        "sudo docker run hello-world --priveleged\n",
        "sudo dockerd --debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0bb-Ugje0DAN",
        "outputId": "b9e9071b-5620-4286-a5cb-c4db2716dac8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Executing docker install script, commit: e5543d473431b782227f8908005543bb4389b8de\n",
            "Warning: the \"docker\" command appears to already exist on this system.\n",
            "\n",
            "If you already have Docker installed, this script can cause trouble, which is\n",
            "why we're displaying this warning and provide the opportunity to cancel the\n",
            "installation.\n",
            "\n",
            "If you installed the current Docker package using this script and are using it\n",
            "again to update Docker, you can safely ignore this message.\n",
            "\n",
            "You may press Ctrl+C now to abort this script.\n",
            "+ sleep 20\n",
            "+ sh -c apt-get update -qq >/dev/null\n",
            "+ sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq apt-transport-https ca-certificates curl >/dev/null\n",
            "+ sh -c install -m 0755 -d /etc/apt/keyrings\n",
            "+ sh -c curl -fsSL \"https://download.docker.com/linux/ubuntu/gpg\" | gpg --dearmor --yes -o /etc/apt/keyrings/docker.gpg\n",
            "+ sh -c chmod a+r /etc/apt/keyrings/docker.gpg\n",
            "+ sh -c echo \"deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu jammy stable\" > /etc/apt/sources.list.d/docker.list\n",
            "+ sh -c apt-get update -qq >/dev/null\n",
            "+ sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq docker-ce docker-ce-cli containerd.io docker-compose-plugin docker-ce-rootless-extras docker-buildx-plugin >/dev/null\n",
            "\n",
            "================================================================================\n",
            "\n",
            "To run Docker as a non-privileged user, consider setting up the\n",
            "Docker daemon in rootless mode for your user:\n",
            "\n",
            "    dockerd-rootless-setuptool.sh install\n",
            "\n",
            "Visit https://docs.docker.com/go/rootless/ to learn about rootless mode.\n",
            "\n",
            "\n",
            "To run the Docker daemon as a fully privileged service, but granting non-root\n",
            "users access, refer to https://docs.docker.com/go/daemon-access/\n",
            "\n",
            "WARNING: Access to the remote API on a privileged Docker daemon is equivalent\n",
            "         to root access on the host. Refer to the 'Docker daemon attack surface'\n",
            "         documentation for details: https://docs.docker.com/go/attack-surface/\n",
            "\n",
            "================================================================================\n",
            "\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\n",
            "See 'docker run --help'.\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.349705051Z] Starting up                                  \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:48.350772434Z] Listener created for HTTP on unix (/var/run/docker.sock) \n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.350823557Z] containerd not running, starting managed containerd \n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.352187489Z] started new containerd process                \u001b[36maddress\u001b[0m=/var/run/docker/containerd/containerd.sock \u001b[36mmodule\u001b[0m=libcontainerd \u001b[36mpid\u001b[0m=4418\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:48.352956102Z] created containerd monitoring client          \u001b[37maddress\u001b[0m=/var/run/docker/containerd/containerd.sock \u001b[37mmodule\u001b[0m=libcontainerd\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:48.353337239Z] 2024/05/02 12:44:48 WARNING: [core] [Channel #1 SubChannel #2] grpc: addrConn.createTransport failed to connect to {Addr: \"/var/run/docker/containerd/containerd.sock\", ServerName: \"localhost\", Attributes: {\"<%!p(networktype.keyType=grpc.internal.transport.networktype)>\": \"unix\" }, }. Err: connection error: desc = \"transport: Error while dialing: dial unix /var/run/docker/containerd/containerd.sock: connect: no such file or directory\"  \u001b[37mlibrary\u001b[0m=grpc\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.393662171Z] starting containerd                           \u001b[36mrevision\u001b[0m=e377cd56a71523140ca6ae87e30244719194a521 \u001b[36mversion\u001b[0m=1.6.31\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.444050775Z] loading plugin \"io.containerd.snapshotter.v1.aufs\"...  \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.447528732Z] skip loading plugin \"io.containerd.snapshotter.v1.aufs\"...  \u001b[36merror\u001b[0m=\"aufs is not supported (modprobe aufs failed: exit status 1 \\\"modprobe: FATAL: Module aufs not found in directory /lib/modules/6.1.58+\\\\n\\\"): skip plugin\" \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.447606941Z] loading plugin \"io.containerd.content.v1.content\"...  \u001b[36mtype\u001b[0m=io.containerd.content.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.447660627Z] loading plugin \"io.containerd.snapshotter.v1.btrfs\"...  \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.447971925Z] skip loading plugin \"io.containerd.snapshotter.v1.btrfs\"...  \u001b[36merror\u001b[0m=\"path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.btrfs (overlay) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin\" \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448004373Z] loading plugin \"io.containerd.snapshotter.v1.devmapper\"...  \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T12:44:48.448050993Z] failed to load plugin io.containerd.snapshotter.v1.devmapper  \u001b[33merror\u001b[0m=\"devmapper not configured\"\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448073730Z] loading plugin \"io.containerd.snapshotter.v1.native\"...  \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448124864Z] loading plugin \"io.containerd.snapshotter.v1.overlayfs\"...  \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448341081Z] loading plugin \"io.containerd.snapshotter.v1.zfs\"...  \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448594430Z] skip loading plugin \"io.containerd.snapshotter.v1.zfs\"...  \u001b[36merror\u001b[0m=\"path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin\" \u001b[36mtype\u001b[0m=io.containerd.snapshotter.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448624406Z] loading plugin \"io.containerd.metadata.v1.bolt\"...  \u001b[36mtype\u001b[0m=io.containerd.metadata.v1\n",
            "\u001b[33mWARN\u001b[0m[2024-05-02T12:44:48.448657300Z] could not use snapshotter devmapper in metadata plugin  \u001b[33merror\u001b[0m=\"devmapper not configured\"\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.448675432Z] metadata content store policy set             \u001b[36mpolicy\u001b[0m=shared\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.452988789Z] loading plugin \"io.containerd.differ.v1.walking\"...  \u001b[36mtype\u001b[0m=io.containerd.differ.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453064924Z] loading plugin \"io.containerd.event.v1.exchange\"...  \u001b[36mtype\u001b[0m=io.containerd.event.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453085799Z] loading plugin \"io.containerd.gc.v1.scheduler\"...  \u001b[36mtype\u001b[0m=io.containerd.gc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453150645Z] loading plugin \"io.containerd.runtime.v1.linux\"...  \u001b[36mtype\u001b[0m=io.containerd.runtime.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453260224Z] loading plugin \"io.containerd.runtime.v2.task\"...  \u001b[36mtype\u001b[0m=io.containerd.runtime.v2\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:48.453331342Z] loading tasks in namespace                    \u001b[37mnamespace\u001b[0m=moby\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453427460Z] loading plugin \"io.containerd.internal.v1.opt\"...  \u001b[36mtype\u001b[0m=io.containerd.internal.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453496353Z] loading plugin \"io.containerd.warning.v1.deprecations\"...  \u001b[36mtype\u001b[0m=io.containerd.warning.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453517608Z] loading plugin \"io.containerd.monitor.v1.cgroups\"...  \u001b[36mtype\u001b[0m=io.containerd.monitor.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453946960Z] loading plugin \"io.containerd.service.v1.containers-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453974065Z] loading plugin \"io.containerd.service.v1.content-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.453994005Z] loading plugin \"io.containerd.service.v1.diff-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454017826Z] loading plugin \"io.containerd.service.v1.images-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454057650Z] loading plugin \"io.containerd.service.v1.introspection-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454082755Z] loading plugin \"io.containerd.service.v1.leases-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454107413Z] loading plugin \"io.containerd.service.v1.namespaces-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454130173Z] loading plugin \"io.containerd.service.v1.snapshots-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454153367Z] loading plugin \"io.containerd.service.v1.tasks-service\"...  \u001b[36mtype\u001b[0m=io.containerd.service.v1\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:48.454178890Z] No RDT config file specified, RDT not configured \n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454195383Z] loading plugin \"io.containerd.grpc.v1.containers\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454220910Z] loading plugin \"io.containerd.grpc.v1.content\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454254629Z] loading plugin \"io.containerd.grpc.v1.diff\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454280386Z] loading plugin \"io.containerd.grpc.v1.events\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454301937Z] loading plugin \"io.containerd.grpc.v1.images\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454324412Z] loading plugin \"io.containerd.grpc.v1.introspection\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454345500Z] loading plugin \"io.containerd.grpc.v1.leases\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454365705Z] loading plugin \"io.containerd.grpc.v1.namespaces\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454387045Z] loading plugin \"io.containerd.grpc.v1.snapshots\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454408641Z] loading plugin \"io.containerd.grpc.v1.tasks\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454432510Z] loading plugin \"io.containerd.grpc.v1.version\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454453327Z] loading plugin \"io.containerd.tracing.processor.v1.otlp\"...  \u001b[36mtype\u001b[0m=io.containerd.tracing.processor.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454480027Z] skip loading plugin \"io.containerd.tracing.processor.v1.otlp\"...  \u001b[36merror\u001b[0m=\"no OpenTelemetry endpoint: skip plugin\" \u001b[36mtype\u001b[0m=io.containerd.tracing.processor.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454498551Z] loading plugin \"io.containerd.internal.v1.tracing\"...  \u001b[36mtype\u001b[0m=io.containerd.internal.v1\n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T12:44:48.454530021Z] failed to initialize a tracing processor \"otlp\"  \u001b[31merror\u001b[0m=\"no OpenTelemetry endpoint: skip plugin\"\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454600211Z] loading plugin \"io.containerd.internal.v1.restart\"...  \u001b[36mtype\u001b[0m=io.containerd.internal.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.454660221Z] loading plugin \"io.containerd.grpc.v1.healthcheck\"...  \u001b[36mtype\u001b[0m=io.containerd.grpc.v1\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.455164751Z] serving...                                    \u001b[36maddress\u001b[0m=/var/run/docker/containerd/containerd-debug.sock\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.455309333Z] serving...                                    \u001b[36maddress\u001b[0m=/var/run/docker/containerd/containerd.sock.ttrpc\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.455418058Z] serving...                                    \u001b[36maddress\u001b[0m=/var/run/docker/containerd/containerd.sock\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:48.455450271Z] sd notification                               \u001b[37merror\u001b[0m=\"<nil>\" \u001b[37mnotified\u001b[0m=false \u001b[37mstate\u001b[0m=\"READY=1\"\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:48.455473391Z] containerd successfully booted in 0.064331s  \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.376807177Z] Golang's threads limit set to 93330          \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.377412996Z] metrics API listening on /var/run/docker/metrics.sock \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.388815504Z] Using default logging driver json-file       \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.389122610Z] No quota support for local volumes in /var/lib/docker/volumes: Filesystem does not support, or has not enabled quotas \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.389636027Z] processing event stream                       \u001b[37mmodule\u001b[0m=libcontainerd \u001b[37mnamespace\u001b[0m=plugins.moby\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.470573304Z] [graphdriver] priority list: [overlay2 fuse-overlayfs btrfs zfs vfs] \n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T12:44:49.484138956Z] failed to mount overlay: invalid argument     \u001b[31mstorage-driver\u001b[0m=overlay2\n",
            "\u001b[31mERRO\u001b[0m[2024-05-02T12:44:49.484298468Z] exec: \"fuse-overlayfs\": executable file not found in $PATH  \u001b[31mstorage-driver\u001b[0m=fuse-overlayfs\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.484395120Z] zfs command is not available: exec: \"zfs\": executable file not found in $PATH  \u001b[37mstorage-driver\u001b[0m=zfs\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.484647717Z] Initialized graph driver vfs                 \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.504853018Z] Max Concurrent Downloads: 3                  \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.504919955Z] Max Concurrent Uploads: 5                    \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.504937463Z] Max Download Attempts: 5                     \n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:49.504993207Z] Loading containers: start.                   \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.506723128Z] processing event stream                       \u001b[37mmodule\u001b[0m=libcontainerd \u001b[37mnamespace\u001b[0m=moby\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.510079946Z] loaded container                              \u001b[37mcontainer\u001b[0m=e7ac2f3d32a609b6fd1332749a94e19fedcee400a077d4ff249bc402caf91fb4 \u001b[37mpaused\u001b[0m=false \u001b[37mrunning\u001b[0m=false\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.529403141Z] restoring container                           \u001b[37mcontainer\u001b[0m=e7ac2f3d32a609b6fd1332749a94e19fedcee400a077d4ff249bc402caf91fb4 \u001b[37mpaused\u001b[0m=false \u001b[37mrestarting\u001b[0m=false \u001b[37mrunning\u001b[0m=false\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.530854051Z] done restoring container                      \u001b[37mcontainer\u001b[0m=e7ac2f3d32a609b6fd1332749a94e19fedcee400a077d4ff249bc402caf91fb4 \u001b[37mpaused\u001b[0m=false \u001b[37mrestarting\u001b[0m=false \u001b[37mrunning\u001b[0m=false\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.530967455Z] Option DefaultDriver: bridge                 \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.530980451Z] Option DefaultNetwork: bridge                \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.530990792Z] Network Control Plane MTU: 1500              \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.531357389Z] unable to initialize firewalld; using raw iptables instead  \u001b[37merror\u001b[0m=\"Failed to connect to D-Bus system bus: dial unix /var/run/dbus/system_bus_socket: connect: no such file or directory\"\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:49.533644807Z] unable to detect if iptables supports xlock: 'iptables --wait -L -n': `# Warning: iptables-legacy tables present, use iptables-legacy to see them\n",
            "iptables v1.8.7 (nf_tables): Could not fetch rule set generation id: Permission denied (you must be root)`  \u001b[36merror\u001b[0m=\"exit status 4\"\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.533805444Z] /usr/sbin/iptables, [-t filter -C FORWARD -j DOCKER-ISOLATION] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.535832209Z] /usr/sbin/iptables, [-t nat -D PREROUTING -m addrtype --dst-type LOCAL -j DOCKER] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.537934531Z] /usr/sbin/iptables, [-t nat -D OUTPUT -m addrtype --dst-type LOCAL ! --dst 127.0.0.0/8 -j DOCKER] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.539939238Z] /usr/sbin/iptables, [-t nat -D OUTPUT -m addrtype --dst-type LOCAL -j DOCKER] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.541906724Z] /usr/sbin/iptables, [-t nat -D PREROUTING]   \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.543716709Z] /usr/sbin/iptables, [-t nat -D OUTPUT]       \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.545555323Z] /usr/sbin/iptables, [-t nat -F DOCKER]       \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.547597730Z] /usr/sbin/iptables, [-t nat -X DOCKER]       \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.549694266Z] /usr/sbin/iptables, [-t filter -F DOCKER]    \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.551638182Z] /usr/sbin/iptables, [-t filter -X DOCKER]    \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.553428207Z] /usr/sbin/iptables, [-t filter -F DOCKER-ISOLATION-STAGE-1] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.555132535Z] /usr/sbin/iptables, [-t filter -X DOCKER-ISOLATION-STAGE-1] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.556743338Z] /usr/sbin/iptables, [-t filter -F DOCKER-ISOLATION-STAGE-2] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.558361679Z] /usr/sbin/iptables, [-t filter -X DOCKER-ISOLATION-STAGE-2] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.559992805Z] /usr/sbin/iptables, [-t filter -F DOCKER-ISOLATION] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.561668690Z] /usr/sbin/iptables, [-t filter -X DOCKER-ISOLATION] \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.563343495Z] /usr/sbin/iptables, [-t nat -n -L DOCKER]    \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.565073285Z] /usr/sbin/iptables, [-t nat -N DOCKER]       \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.566715061Z] daemon configured with a 15 seconds minimum shutdown timeout \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.566751645Z] start clean shutdown of all containers with a 15 seconds timeout... \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.567723424Z] Cleaning up old mountid : start.             \n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.568203445Z] Cleaning up old mountid : done.              \n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:49.568531922Z] stopping event stream following graceful shutdown  \u001b[36merror\u001b[0m=\"context canceled\" \u001b[36mmodule\u001b[0m=libcontainerd \u001b[36mnamespace\u001b[0m=plugins.moby\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:49.568597625Z] stopping event stream following graceful shutdown  \u001b[36merror\u001b[0m=\"context canceled\" \u001b[36mmodule\u001b[0m=libcontainerd \u001b[36mnamespace\u001b[0m=moby\n",
            "\u001b[36mINFO\u001b[0m[2024-05-02T12:44:49.568626330Z] stopping healthcheck following graceful shutdown  \u001b[36mmodule\u001b[0m=libcontainerd\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.568958158Z] received signal                               \u001b[37msignal\u001b[0m=terminated\n",
            "\u001b[37mDEBU\u001b[0m[2024-05-02T12:44:49.569066762Z] sd notification                               \u001b[37merror\u001b[0m=\"<nil>\" \u001b[37mnotified\u001b[0m=false \u001b[37mstate\u001b[0m=\"STOPPING=1\"\n",
            "failed to start daemon: Error initializing network controller: error obtaining controller instance: failed to register \"bridge\" driver: failed to create NAT chain DOCKER: iptables failed: iptables -t nat -N DOCKER: iptables v1.8.7 (nf_tables): Could not fetch rule set generation id: Permission denied (you must be root)\n",
            "\n",
            " (exit status 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'sudo curl -fsSL https://get.docker.com/ | sh\nsudo usermod -aG docker root\nsudo docker run hello-world --priveleged\nsudo dockerd --debug\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0c2163807a92>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sudo curl -fsSL https://get.docker.com/ | sh\\nsudo usermod -aG docker root\\nsudo docker run hello-world --priveleged\\nsudo dockerd --debug\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'sudo curl -fsSL https://get.docker.com/ | sh\nsudo usermod -aG docker root\nsudo docker run hello-world --priveleged\nsudo dockerd --debug\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "sudo apt update -qq\n",
        "\n",
        "sudo apt install apt-transport-https ca-certificates curl software-properties-common -qq\n",
        "\n",
        "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n",
        "\n",
        "sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"\n",
        "\n",
        "sudo apt update -qq\n",
        "\n",
        "sudo apt install docker-ce\n",
        "\n",
        "docker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "WxZ_DR7a2aNJ",
        "outputId": "ac39b669-dbe5-4be5-f953-d4a87e7ea58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.16).\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "apt-transport-https is already the newest version (2.4.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "Repository: 'deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable'\n",
            "Description:\n",
            "Archive for codename: bionic components: stable\n",
            "More info: https://download.docker.com/linux/ubuntu\n",
            "Adding repository.\n",
            "Press [ENTER] to continue or Ctrl-c to cancel.Aborted.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '\nsudo apt update -qq\n    \nsudo apt install apt-transport-https ca-certificates curl software-properties-common -qq\n    \ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n    \nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"\n    \nsudo apt update -qq\n    \nsudo apt install docker-ce\n    \ndocker\n' died with <Signals.SIGINT: 2>.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7b0173f8b2e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nsudo apt update -qq\\n    \\nsudo apt install apt-transport-https ca-certificates curl software-properties-common -qq\\n    \\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\\n    \\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"\\n    \\nsudo apt update -qq\\n    \\nsudo apt install docker-ce\\n    \\ndocker\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '\nsudo apt update -qq\n    \nsudo apt install apt-transport-https ca-certificates curl software-properties-common -qq\n    \ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n    \nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\"\n    \nsudo apt update -qq\n    \nsudo apt install docker-ce\n    \ndocker\n' died with <Signals.SIGINT: 2>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install udocker\n",
        "!udocker --allow-root install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thNQadyS12jB",
        "outputId": "e479ec41-8ab9-44f7-8d1e-b0c1df07ad10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting udocker\n",
            "  Downloading udocker-1.3.16-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112.6/119.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: udocker\n",
            "Successfully installed udocker-1.3.16\n",
            "Info: creating repo: /root/.udocker\n",
            "Info: udocker command line interface 1.3.16\n",
            "Info: searching for udockertools >= 1.2.11\n",
            "Info: installing udockertools 1.2.11\n",
            "Info: installation of udockertools successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root run  \\\n",
        "  <image-repository>:tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqJq1dE-14Qs",
        "outputId": "045b46fc-26d1-4776-879d-741aeb5ca476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: image-repository: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV9LT-Mq16pH",
        "outputId": "8ad01a0f-8ef3-4066-e95f-c4c847f35191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTAINER ID                         P M NAMES              IMAGE               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!docker pull lightly/worker:latest\n",
        "!docker run --shm-size=\"1024m\" --rm -it lightly/worker:latest sanity_check=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8hbm-WHqaeM",
        "outputId": "46a70214-0114-41a5-f6bd-5fa1cc52e7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\n",
            "See 'docker run --help'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!docker run --shm-size \"1024m\" --gpus all --rm -it \\\n",
        "    -v /home/user/project_xyz/input:/input_mount:ro \\\n",
        "    -v /home/user/project_xyz/lightly:/lightly_mount \\\n",
        "    -e LIGHTLY_TOKEN='a07442857e87e75f4d5d71ed5c3e6572203db3916bafcac7' \\\n",
        "    -e LIGHTLY_WORKER_ID='662954bf92e9f46a03d7165a' \\\n",
        "    lightly/worker:latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOps8h58eR4-",
        "outputId": "3dab4635-84b9-48a3-e1fd-3b7afa6c0489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.\n",
            "See 'docker run --help'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh-jM2L7flGL",
        "outputId": "aee30c51-a0f6-4bb9-dfa7-7172088d7fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_carpeta_drive = '/content/drive/MyDrive/ALYOLO/datasets'\n",
        "\n",
        "# Opcional: Copiar la carpeta a tu entorno local de Colab para mejorar el rendimiento\n",
        "# Puedes omitir este paso si prefieres trabajar directamente desde Drive,\n",
        "# pero ten en cuenta que puede ser más lento para operaciones de lectura/escritura intensivas.\n",
        "!cp -r \"{ruta_carpeta_drive}\" ./datasets"
      ],
      "metadata": {
        "id": "uegNce3qed4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!docker pull lightly/worker:latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdU2EedxziEc",
        "outputId": "792ed416-45f8-400d-94de-0b37af562f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: docker: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsGARG34zjzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from lightly.api import ApiWorkflowClient\n",
        "from lightly.openapi_generated.swagger_client import DatasetType, DatasourcePurpose\n",
        "\n",
        "###### CHANGE THESE 2 VARIABLES\n",
        "DATASET_PATH = Path(\"CHANGE_ME\")  # e.g., Path(\"/path/to/images\") or Path(\"clothing_dataset\")\n",
        "LIGHTLY_TOKEN = \"a07442857e87e75f4d5d71ed5c3e6572203db3916bafcac7\"  # Copy from https://app.lightly.ai/preferences\n",
        "######\n",
        "\n",
        "assert DATASET_PATH.exists(), f\"Dataset path {DATASET_PATH} does not exist.\"\n",
        "\n",
        "# Create the Lightly client to connect to the API.\n",
        "client = ApiWorkflowClient(token=LIGHTLY_TOKEN)\n",
        "\n",
        "# Register the Lightly Worker.\n",
        "worker_id = client.register_compute_worker(name=\"first-worker\")\n",
        "\n",
        "# Create the dataset on the Lightly Platform.\n",
        "# See our guide for more details and options:\n",
        "# https://docs.lightly.ai/docs/set-up-your-first-dataset\n",
        "client.create_dataset(\n",
        "    dataset_name=f\"first_dataset__{datetime.now().strftime('%Y_%m_%d__%H_%M_%S')}\",\n",
        "    dataset_type=DatasetType.IMAGES,\n",
        ")\n",
        "\n",
        "# Configure the datasources.\n",
        "# See our guide for more details and options:\n",
        "# https://docs.lightly.ai/docs/set-up-your-first-dataset\n",
        "client.set_local_config(purpose=DatasourcePurpose.INPUT)\n",
        "client.set_local_config(purpose=DatasourcePurpose.LIGHTLY)\n",
        "\n",
        "# Schedule a run on the dataset to select 50 diverse samples.\n",
        "# See our guide for more details and options:\n",
        "# https://docs.lightly.ai/docs/run-your-first-selection\n",
        "scheduled_run_id = client.schedule_compute_worker_run(\n",
        "    worker_config={\"shutdown_when_job_finished\": True},\n",
        "    selection_config={\n",
        "        \"n_samples\": 50,\n",
        "        \"strategies\": [\n",
        "            {\"input\": {\"type\": \"EMBEDDINGS\"}, \"strategy\": {\"type\": \"DIVERSITY\"}}\n",
        "        ],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Print the next commands\n",
        "print(\n",
        "    f\"\\nDocker Run command: \\n\"\n",
        "    f\"\\033[7m\"\n",
        "    f\"docker run --shm-size='1024m' --rm -it \\\\\\n\"\n",
        "    f\"\\t-v '{DATASET_PATH.absolute()}':/input_mount:ro \\\\\\n\"\n",
        "    f\"\\t-v '{Path('lightly').absolute()}':/lightly_mount \\\\\\n\"\n",
        "    f\"\\t-e LIGHTLY_TOKEN={LIGHTLY_TOKEN} \\\\\\n\"\n",
        "    f\"\\t-e LIGHTLY_WORKER_ID={worker_id} \\\\\\n\"\n",
        "    \"\\tlightly/worker:latest\\n\"\n",
        "    f\"\\033[0m\"\n",
        ")\n",
        "print(\n",
        "    \"\\nLightly Serve command:\\n\"\n",
        "    f\"\\033[7m\"\n",
        "    f\"lightly-serve input_mount='{DATASET_PATH.absolute()}' \"\n",
        "    f\"lightly_mount='{Path('lightly').absolute()}'\\n\"\n",
        "    f\"\\033[0m\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "xYjclQEPxk_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wjFyfjbZytj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics.utils.downloads import GITHUB_ASSETS_STEMS\n",
        "from ultralytics import YOLO, settings\n",
        "\n",
        "model = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/datasets/custom_dataset.yaml\",\n",
        "    flipud=0.5,\n",
        "    epochs=50,\n",
        "    seed=0,\n",
        "    batch=8,\n",
        "    imgsz=960,\n",
        "    name=\"random-200\",\n",
        ")  # train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WYNN1k_eQiF",
        "outputId": "52396395-83f3-4b51-d1af-43fc21126d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/content/datasets/custom_dataset.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=960, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=random-2002, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/random-2002\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5587426  ultralytics.nn.modules.head.Detect           [6, [256, 512, 512]]          \n",
            "Model summary: 365 layers, 43634466 parameters, 43634450 gradients, 165.4 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/random-2002', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/train/labels.cache... 843 images, 3 backgrounds, 0 corrupt: 100%|██████████| 843/843 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/valid/labels.cache... 302 images, 0 backgrounds, 0 corrupt: 100%|██████████| 302/302 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/random-2002/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 960 train, 960 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/random-2002\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/106 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo detect val model=runs/detect/random-200/weights/best.pt \\\n",
        "    data=data/custom_dataset.yaml \\\n",
        "    batch=8 imgsz=960 split=val"
      ],
      "metadata": {
        "id": "Q4-NaFJ6f4D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Código de ejemplo para sincronizar el conjunto de datos Lightly para seleccionar aleatoriamente 400\n",
        "# imágenes\n",
        "from lightly.api import ApiWorkflowClient\n",
        "\n",
        "# Cree el cliente Lightly para conectarse a la API.\n",
        "client = ApiWorkflowClient(token=\"a07442857e87e75f4d5d71ed5c3e6572203db3916bafcac7\", dataset_id=\"Lightly-0eb087aeb548a6c5357f4f92e42b9991405eede39ec7d37717cff24bfa30c5fb\")\n",
        "\n",
        "# Descargue los nombres de archivos seleccionados de Lightly\n",
        "filenames = client.export_filenames_by_tag_name(\n",
        "    tag_name=\"initial-tag\"  # name of the tag in the dataset\n",
        ")\n",
        "\n",
        "# Necesitamos reformatear un poco las cadenas.\n",
        "filenames = filenames.split('\\n')\n",
        "filenames = ['all_fields_lincolnbeet/all/' + f + '\\n' for f in filenames]\n",
        "\n",
        "# Cargamos la configuración de YOLO para el conjunto de entrenamiento.\n",
        "with open('all_fields_lincolnbeet/all_fields_lincolnbeet_train_.txt', 'r') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "# Solo conservamos los nombres de archivos de entrenamiento que han sido seleccionados por Lightly\n",
        "data_filtered = list(filter(lambda x: x in filenames, data))\n",
        "\n",
        "# Cree un nuevo archivo de texto con los datos ligeramente seleccionados\n",
        "with open('all_fields_lincolnbeet/all_fields_lincolnbeet_train_random-400.txt', 'w') as f:\n",
        "    f.writelines(data_filtered)"
      ],
      "metadata": {
        "id": "ATtYrWhogCJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduled_run_id = client.schedule_compute_worker_run(\n",
        "    worker_config={\n",
        "    },\n",
        "    selection_config={\n",
        "        \"n_samples\": 400,\n",
        "        \"strategies\": [\n",
        "            {\n",
        "                \"input\": {\n",
        "                    \"type\": \"RANDOM\",\n",
        "                    \"random_seed\": 42, # optional, for reproducibility\n",
        "                },\n",
        "                \"strategy\": {\n",
        "                    \"type\": \"WEIGHTS\",\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "2-f3y_KviGpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduled_run_id = client.schedule_compute_worker_run(\n",
        "    worker_config={\n",
        "        \"enable_training\": True,\n",
        "        \"training\": {\n",
        "                \"task_name\": \"yolov8-random-200-detection\",\n",
        "        },\n",
        "    },\n",
        "    selection_config={\n",
        "        \"n_samples\": 400,\n",
        "        \"strategies\": [\n",
        "            {\n",
        "                # strategy to find diverse objects\n",
        "                \"input\": {\n",
        "                    \"type\": \"EMBEDDINGS\",\n",
        "                    \"task\": \"yolov8-random-200-detection\",\n",
        "                },\n",
        "                \"strategy\": {\n",
        "                    \"type\": \"DIVERSITY\",\n",
        "                },\n",
        "            },\n",
        "            {\n",
        "                # strategy to balance the class ratios\n",
        "                \"input\": {\n",
        "                    \"type\": \"PREDICTIONS\",\n",
        "                    \"name\": \"CLASS_DISTRIBUTION\",\n",
        "                    \"task\": \"yolov8-random-200-detection\",\n",
        "                },\n",
        "                \"strategy\": {\n",
        "                    \"type\": \"BALANCE\",\n",
        "                    \"target\": {\n",
        "                        \"sugar beet\": 0.3,\n",
        "                        \"weed\": 0.7\n",
        "                    },\n",
        "                },\n",
        "            },\n",
        "            {\n",
        "                # strategy to prioritize images with more objects (frequency)\n",
        "                \"input\": {\n",
        "                    \"type\": \"SCORES\",\n",
        "                    \"task\": \"yolov8-random-200-detection\",\n",
        "                    \"score\": \"object_frequency\",\n",
        "                },\n",
        "                \"strategy\": {\"type\": \"WEIGHTS\"},\n",
        "            },\n",
        "            {\n",
        "                # strategy to use prediction score (Active Learning)\n",
        "                \"input\": {\n",
        "                    \"type\": \"SCORES\",\n",
        "                    \"task\": \"yolov8-random-200-detection\",\n",
        "                    \"score\": \"objectness_least_confidence\",\n",
        "                },\n",
        "                \"strategy\": {\"type\": \"WEIGHTS\"},\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    lightly_config={\n",
        "        \"trainer\": {\n",
        "            \"max_epochs\": 1,\n",
        "            \"precision\": 16\n",
        "        },\n",
        "        \"loader\": {\n",
        "            \"batch_size\": 128\n",
        "        },\n",
        "        \"collate\": {\n",
        "            \"vf_prob\": 0.5, # enable vertical flip\n",
        "            \"rr_prob\": 0.5, # enable random rotation\n",
        "        }\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "Ez00Plg0iyjb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}